#!/bin/bash
[ -z "$bin" ] && (echo "\$bin not defined"; exit 1)
[ -z "$VIDEO_DIR" ] && VIDEO_DIR="$HOME/Videos/youtube"
LOG_DIR="${XDG_CACHE_HOME:-$HOME/.cache}/dotfiles"
LOG_FILE="$LOG_DIR/tsp_ytdlp.log"
QUEUED_URLS_FILE="$LOG_DIR/active_downloads.txt"
RETRY_URLS_FILE="$LOG_DIR/retry_downloads.txt"
COOKIES="$HOME/source/private/cookies.firefox-private.txt"

mkdir -p "$LOG_DIR" || { echo "Failed to create log directory: $LOG_DIR"; exit 1; }

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$LOG_FILE"
}

atomic_append() {
    local file="$1"
    local content="$2"
    local temp_file="$LOG_DIR/tempfiles/$(basename "$file").tmp.$.$RANDOM"
    
    mkdir -p "$LOG_DIR/tempfiles"
    touch "$file" 2>/dev/null || true
    cat "$file" > "$temp_file"
    echo "$content" >> "$temp_file"
    mv "$temp_file" "$file"
}

atomic_remove_line() {
    local file="$1"
    local line="$2"
    local temp_file="$LOG_DIR/tempfiles/$(basename "$file").tmp.$.$RANDOM"
    
    mkdir -p "$LOG_DIR/tempfiles"
    if [ -f "$file" ]; then
        grep -v "^$line$" "$file" > "$temp_file" 2>/dev/null || true
        mv "$temp_file" "$file"
    fi
}

atomic_move_file() {
    local src="$1"
    local dest="$2"
    local temp_file="$LOG_DIR/tempfiles/$(basename "$dest").tmp.$.$RANDOM"
    
    mkdir -p "$LOG_DIR/tempfiles"
    if [ -f "$src" ]; then
        cat "$src" >> "$temp_file" 2>/dev/null || true
        cat "$dest" >> "$temp_file" 2>/dev/null || true
        mv "$temp_file" "$dest"
        true > "$src"
    fi
}

should_skip_duplicate_url() {
    local url="$1"
    local status
    status=$(tsp -l | grep "$url" | head -1 | awk '{print $2}' 2>/dev/null)
    [[ "$status" == "queued" || "$status" == "finished" ]]
}

recover_queued_urls() {
    [ ! -f "$QUEUED_URLS_FILE" ] && return
    local recovered_count=0
    while IFS= read -r queued_url; do
        [ -z "$queued_url" ] && continue
        if ! should_skip_duplicate_url "$queued_url"; then
            atomic_append "$RETRY_URLS_FILE" "$queued_url"
            ((recovered_count++))
        fi
    done < "$QUEUED_URLS_FILE"
    
    if [ $recovered_count -gt 0 ]; then
        true > "$QUEUED_URLS_FILE"
        log "Recovered $recovered_count URLs to retry list"
    fi
}

mkdir -p "$VIDEO_DIR" || { echo "Failed to create video directory: $VIDEO_DIR"; exit 1; }
mkdir -p "$LOG_DIR"

process_retry_list() {
    [ ! -f "$RETRY_URLS_FILE" ] && return
    local retry_count=0
    while IFS= read -r retry_url; do
        [ -z "$retry_url" ] && continue
        
        if should_skip_duplicate_url "$retry_url"; then
            log "Deduped retry URL (already queued/finished): $retry_url"
            ((retry_count++))
            continue
        fi
        
        local retry_video_dir="$HOME/Videos/youtube"
        
        if [[ "$retry_url" != *"youtube.com"* ]] && [ -x "$HOME/source/private/get_video_dir.sh" ]; then
            if custom_dir=$("$HOME/source/private/get_video_dir.sh" "$retry_url" 2>/dev/null); then
                if [ -n "$custom_dir" ]; then
                    if [[ "$custom_dir" =~ ^[/~] ]] || [[ "$custom_dir" =~ ^\$HOME ]]; then
                        custom_dir="${custom_dir//\$HOME/$HOME}"
                        if mkdir -p "$custom_dir" 2>/dev/null; then
                            retry_video_dir="$custom_dir"
                        fi
                    fi
                fi
            fi
        fi
        
        notify-send t 3000 "Retrying: $retry_url"
        local title
        title=$(yt-dlp --print filename --cookies "$COOKIES" "$retry_url" -o "%(title)s" 2>/dev/null || echo "unknown")
        
        if [ "$retry_video_dir" != "$HOME/Videos/youtube" ]; then
            tsp -L "retry: $title | $retry_url" env VIDEO_DIR="$retry_video_dir" "$bin/_tsp_download_video_helper" "$retry_url"
        else
            tsp -L "retry: $title | $retry_url" "$bin/_tsp_download_video_helper" "$retry_url"
        fi
        ((retry_count++))
    done < "$RETRY_URLS_FILE"
    
    true > "$RETRY_URLS_FILE"
    if [ $retry_count -gt 0 ]; then
        log "Processed $retry_count URLs from retry list"
    fi
}

recover_queued_urls
process_retry_list

url="$1"
if [ -z "$url" ]; then
    notify-send "Error: No URL provided üò†"
    exit 1
fi

if [[ ! "$url" =~ ^https?:// ]]; then
    notify-send "Error: Not a URL - $url üëéüëé"
    exit 1
fi

if [[ "$url" != *"youtube.com"* ]] && [ -x "$HOME/source/private/get_video_dir.sh" ]; then
    if custom_dir=$("$HOME/source/private/get_video_dir.sh" "$url" 2>/dev/null); then
        if [ -n "$custom_dir" ] && [ "$custom_dir" != "$VIDEO_DIR" ]; then
            if [[ "$custom_dir" =~ ^[/~] ]] || [[ "$custom_dir" =~ ^\$HOME ]]; then
                custom_dir="${custom_dir//\$HOME/$HOME}"
                if mkdir -p "$custom_dir" 2>/dev/null; then
                    VIDEO_DIR="$custom_dir"
                    log "Custom directory detected for URL: $url -> $VIDEO_DIR"
                else
                    log "ERROR: Failed to create custom directory: $custom_dir, using default"
                fi
            else
                log "WARNING: get_video_dir.sh returned invalid directory path: $custom_dir"
            fi
        else
            log "INFO: get_video_dir.sh returned empty result, using default directory for URL: $url"
        fi
    else
        log "INFO: get_video_dir.sh returned empty result, using default directory for URL: $url"
    fi
else
    if [[ "$url" == *"youtube.com"* ]]; then
        log "INFO: YouTube URL detected, using default directory: $VIDEO_DIR"
    else
        log "INFO: get_video_dir.sh not found or not executable, using default directory"
    fi
fi

notification_id=$(echo "$url" | md5sum | cut -d' ' -f1)
notification_hint="string:x-canonical-private-synchronous:$notification_id"

if should_skip_duplicate_url "$url"; then
    notify-send -t 1200 -h "$notification_hint" "URL already queued/finished: $url üï∫"
    log "Deduped URL (already queued/finished): $url"
    exit 0
fi

notify-send -t 0 -h "$notification_hint" "Processing: $url üîÑ"

if [[ "$url" == *"youtube.com"* ]]; then
    title_format="%(channel)s_%(title)s"
else
    title_format="%(title)s"
fi

if ! title=$(yt-dlp --print filename --cookies "$COOKIES" "$url" -o "$title_format"); then
    log "Failed to get filename for $url"
    notify-send -t 3000 -h "$notification_hint" "Failed to get filename for $url ‚ùå"
    exit 1
fi

atomic_append "$QUEUED_URLS_FILE" "$url"

if [ "$VIDEO_DIR" != "$HOME/Videos/youtube" ]; then
    tsp -L "yt-dlp: $title | $url" env VIDEO_DIR="$VIDEO_DIR" "$bin/_tsp_download_video_helper" "$url"
else
    tsp -L "yt-dlp: $title | $url" "$bin/_tsp_download_video_helper" "$url"
fi

tsp_exit_code="$?"
if [ $tsp_exit_code -ne 0 ]; then
    atomic_remove_line "$QUEUED_URLS_FILE" "$url"
    log "ERROR: Failed to queue download. TSP exit code: $tsp_exit_code - $url -> $title"
    notify-send -t 3000 -h "$notification_hint" "Error: Failed to queue download ü§Ø -> $title"
    exit "$tsp_exit_code"
else
    log "Successfully queued tsp command for: $url -> $title"
    notify-send -t 3000 -h "$notification_hint" "Download queued: $title üèÉ‚ôÇÔ∏è"
fi
